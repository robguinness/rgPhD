%\section{Motivation - Computers that Know What You Want or Need}
We are currently witnessing an era of technological convergence that rivals some of the great technological upheavals of modern history. The internal combustion engine, the electric lamp, the transistor, the jetliner, the artificial satellite---it is in this same revered company that we can place the technological revolution we are now undergoing. It is difficult, however, to pin this current revolution down to any one particular technology because it is in fact the result of at least four major technologies converging over a period of a few decades: (1) mobile telecommunication devices, (2) the Internet, (3) positioning technologies, and (4) a wide range of inexpensive yet highly capable sensors, namely microelectromechanical systems (MEMS). All of these technologies came to a technological crossroads in the late 20th century and early 21st century. The first major manifestation of this convergence, especially with respect to consumer markets, is the so-called ``smartphone'', of which there are more than one billion in use worldwide today. This number is likely to surpass two billion by 2015. These devices allow their users to stay ``connected'' virtually everywhere they go, and consequently anyone can connect to these one billion plus users from any networked device, including desktop computers and ``land-line'' phones--no matter where the user is located or travelling to. Ironically, in many technologically advanced societies, it is now considered a societal and/or behavioral challenge for one to go ``off the grid'' or ``disconnected'' for any extended period of time.

It is the author's view that the smartphone is only the first manifestation of this technological revolution. Many other so-called ``smart'' devices are soon to follow: ``smartwatches'' and the use  of various wearable sensors may soon become a mainstay consumer habit. In addition, the same technologies that have made smartphones possible and popular are quickly making their way into existing everyday devices, including cars, home appliances, and even toothbrushes. It would be  na\"{\i}ve to speculate exactly how this revolution will play out in the coming decades, but is clear is that it is already changing the lifestyles, habits, and possibilities of people living in the early 21st century, especially those who can afford these (currently) ``high-end'' consumer devices.

Aside from being a convergence of new technologies, is there any unifying concept or principle that is underlying this revolution? Some would argue that it is the increased levels of \emph{mobility} that these technologies provide. Others have rallied under the banner of \emph{ubiquitous computing} or \emph{pervasive computing}, which describes the fact that computing devices can now be found nearly everywhere one looks. Certainly these are two important characteristics giving wind to this revolution, but we argue in this thesis towards another underlying principle that provides a common thread and deep insight into how our relationship to these computing devices is changing.

One common development, of course, is the increasing ability of computing devices to fulfill various user desires, e.g. download large amounts of data at high speeds, capture or render various high-quality multimedia content, store and edit content in various ways, etc. What is not advancing or expanding---at least, not at any considerable rate---is the patience or attention span of the users themselves. Therefore, users are expecting (consciously or not) that the devices will ``do more'' with essentially the same total quantity and quality of human input. Fortunately, however, these devices are rapidly advancing in their ability to know what their users want or need---without the user having to explicitly formulate and express these desires to the computer. This is the goal under which this thesis is motivated and focused---to improve our understanding of how computing devices can better understand us.

We are not there yet. In many ways, smartphones are not yet ``smart''. They have the ``braun"" and not the brains, in the sense that they are powerful and capable but deficient in understanding the user's needs. This thesis aims to improve the state-of-the-art in a computer's ability to understand human situations or contexts. Mobile computing researchers have adopted the term \emph{context awareness} to refer to this ability. In particular, this thesis will focus on how low-cost sensors can be utilized for building context awareness. The reason for focusing on low-cost is motivated by a desire that the developed systems and methodologies will have the widest impact possible for a large number of people. As technology advances and costs of these devices are driven lower and lower, the range of applications and impacts they will have will become wider and wider.

\section{Research Objectives}

The overall goal of this thesis were described in general terms above, but in this section we briefly define the detailed research objectives of the thesis. They are as follows:

\begin{itemize}
  \item to elucidate a fresh interpretation and model for the concept of context awareness.
  \item to introduce and formalize a methodology for achieving context awareness in computing devices.
  \item to present the state-of-the-art in relevant smartphone technology, especially with regards to sensors that can be used for context awareness.
  \item to evaluate and describe additional sensors that can be used for context awareness in various scenarios and applications.
  \item to present implementation details and test results of a set of experiments related to context-aware smartphone applications.
  \item to present implementation details and test results of second set of experiments related to context-aware maritime navigation applications.
  \item to present conclusions based on the results of this research and suggest future avenues for further research.
\end{itemize}

\section{Related Work}
The set of relevant related work concerning this thesis is quite large and varied, as includes fields as diverse as machine learning, location technologies, sensor technologies, and various application-specific topics.  As such, the related work will be covered in greatest detail in the topic-specific chapters that are to follow. In this section, however, we briefly review the research literature that is most similar to this thesis topic.

~5-10 paragraphs...

\section{Author's Contribution}
(Laura's text left as example. Will compose this towards the end of the process...) In this thesis a novel pedestrian navigation system is presented. Two concepts are developed, namely a "visual gyroscope" providing the user heading and a "visual odometer" providing the translation. Author's contributions include also a system developed for pedestrian urban navigation, utilizing the visual gyroscope, visual odometer and signal carrier information obtained from at least two GNSS satellites.

All calculations are of a sufficiently low complexity to be adopted for navigation with current smartphones. The main contributions of the thesis are as follows:

\begin{itemize}
\item A visual gyroscope with lower computational requirements suitable for present smartphones. The visual gyroscope is based on observing heading, pitch and roll of the camera, using vanishing points.
\item A novel error detection method which provides accurate and reliable navigation despite the unforeseeable motions of a pedestrian. The algorithm makes the visual gyroscope suitable for pedestrian navigation.
\item A visual odometer, namely a method to resolve translation from images using a monocular camera. The visual odometer is suitable to be used also in indoor environments which are usually poor in features. It is feasible for seamless navigation since it leans on the visual gyroscope's orientation information and needs only the approximate height of the camera as prior information.
\item A vision-aided differentiated carrier phase navigation system for pedestrians. The method is leaner than previous similar solutions. The system is independent from other sensors than the camera and the GNSS receiver because it encompasses the visual gyroscope and visual odometer providing the orientation and motion information.
\end{itemize}

The core contributions of Chapters 4-6 were first presented in \cite{P4}, \cite{P5}, \cite{P6}, \cite{P3}, \cite{P2}, \cite{P8} and \cite{P7} in which the author of the thesis is the first author and in \cite{P9} in which the author of the thesis is a co-author.

\section{Thesis Outline}
(Laura's text left as example. Will compose this when chapters are more or less finalized...) In \textbf{Chapter 2}, the most prevalent systems used in pedestrian navigation - i.e. GNSS, WLAN and self-contained sensors - are presented. The computer vision principles relevant in vision-aided navigation are discussed in \textbf{Chapter 3} with an emphasis on the methods and algorithms used in the thesis. \textbf{Chapter 4} introduces the concept of a "visual gyroscope" and the novel error detection algorithm. The feasibility and challenges of the visual gyroscope are discussed as well as the effect of different camera and setup characteristics on the accuracy and applicability of the method in pedestrian navigation. In \textbf{Chapter 5} a concept of "visual odometer" is presented. The mathematics, strengths and challenges of the visual odometer and its utilization are discussed. \textbf{Chapter 6} presents results from various experiments integrating the visual gyroscope and odometer, both for indoor and urban pedestrian navigation. In \textbf{Chapter 7} the vision-aided differentiated carrier phase navigation system for pedestrians, results from experiments and its feasibility for urban pedestrian navigation are discussed. \textbf{Chapter 8} provides conclusions and recommendations for future research.